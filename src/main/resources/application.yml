server:
  port: 8080

spring:
  application:
    name: intelligent-qa-system
  
  # Database Configuration
  datasource:
    # 开发环境使用H2纯内存数据库（重启后数据清空）
    url: jdbc:h2:mem:qadb;DB_CLOSE_DELAY=-1
    driver-class-name: org.h2.Driver
    username: sa
    password: 
    # 生产环境MySQL配置
    # url: jdbc:mysql://localhost:3306/qa_system?useUnicode=true&characterEncoding=utf-8&serverTimezone=Asia/Shanghai
    # driver-class-name: com.mysql.cj.jdbc.Driver
    # username: root
    # password: your_password
  
  h2:
    console:
      enabled: true
      path: /h2-console
  
  jpa:
    database-platform: org.hibernate.dialect.H2Dialect
    hibernate:
      ddl-auto: update
    show-sql: false
    properties:
      hibernate:
        format_sql: false
  
  # Redis Configuration  
  data:
    redis:
      host: localhost
      port: 6379
      # password: your_redis_password
      timeout: 3000ms
  
  # File Upload Configuration
  servlet:
    multipart:
      max-file-size: 500MB
      max-request-size: 500MB

# Application Custom Configuration
app:
  # 文档存储路径
  document:
    storage-path: ./uploads
    max-file-size: 524288000  # 500MB
    allowed-types: pdf,md,markdown,txt
  
  # 文档切片配置
  chunking:
    chunk-size: 1500         # 增大分片以保留完整段落和表格
    chunk-overlap: 200       # 增大重叠避免信息丢失
    min-chunk-size: 200      # 最小分片大小
  
  # 向量数据库配置
  vector:
    # 使用内存向量存储(开发模式)或Milvus
    type: memory  # memory / milvus
    milvus:
      host: localhost
      port: 19530
      collection-name: document_chunks
      dimension: 1536  # Azure Embedding Dimension
  
  # Embedding模型配置
  embedding:
    type: azure  # mock / dashscope / openai / azure
    dashscope:
      api-key: ${DASHSCOPE_API_KEY:}
      model: text-embedding-v2
    openai:
      api-key: ${OPENAI_API_KEY:}
      model: text-embedding-3-small
    azure:
      api-key: ${AZURE_OPENAI_API_KEY:}
      endpoint: https://odm-rag-test.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-02-01
      deployment-name: text-embedding-3-small
  
  # LLM配置
  llm:
    # 主模型 - 使用 Azure OpenAI Responses API (gpt-5.2)
    primary:
      type: azure
      api-type: responses  # 使用 Responses API (适用于 gpt-5.x 系列)
      api-key: ${AZURE_OPENAI_API_KEY:}
      model: gpt-5.2-chat
      endpoint: https://odm-rag-test.openai.azure.com/openai/responses?api-version=2025-04-01-preview
      timeout: 120000  # gpt-5.x 可能需要更长处理时间
      max-tokens: 4096  # gpt-5.x 支持更大的输出
    # 备用模型 (这里我们用它来配置 GPT-4.1)
    fallback:
      type: gpt-4.1  # 使用模型名称匹配，确保 LLMRouter 不会再次返回 Primary
      api-type: chat
      api-key: ${AZURE_OPENAI_API_KEY:}
      model: gpt-4.1
      endpoint: https://odm-rag-test.openai.azure.com/openai/deployments/gpt-4.1/chat/completions?api-version=2025-01-01-preview
      timeout: 60000
      max-tokens: 2048
    # 重试配置
    retry:
      max-attempts: 3
      delay-ms: 1000
      multiplier: 2.0
  
  # 上下文管理配置
  context:
    max-history-rounds: 10      # 最大保留对话轮数
    max-context-tokens: 4000    # 最大上下文token数
    summary-threshold: 6        # 触发摘要的对话轮数
  
  # RAG检索配置
  rag:
    top-k: 10
    similarity-threshold: 0.6
    max-tokens: 2000
    # 启用上下文增强 (Contextual Retrieval)
    contextual-retrieval-enabled: true
    # 小文档阈值 (chunk数量)
    small-document-threshold: 99999 # 实际上由于我们要保存所有文档全文，这个阈值可以设大一点或者在代码里忽略
    rerank-enabled: false       # 是否启用重排序

# Logging
logging:
  level:
    root: INFO
    com.example.qa: DEBUG
    org.springframework.web: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
